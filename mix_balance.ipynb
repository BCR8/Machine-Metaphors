{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "char_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BCR8/Machine-Metaphors/blob/master/mix_balance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4T2cBVI0s1g",
        "colab_type": "text"
      },
      "source": [
        "# A Char-RNN Implementation in Tensorflow\n",
        "---\n",
        "CharRNN was a well known generative text model (character level LSTM) created by Andrej Karpathy. It allowed easy training and generation of arbitrary text with many hilarious results:\n",
        "\n",
        "  * Music: abc notation\n",
        "<https://highnoongmt.wordpress.com/2015/05/22/lisls-stis-recurrent-neural-networks-for-folk-music-generation/>,\n",
        "  * Irish folk music\n",
        "<https://soundcloud.com/seaandsailor/sets/char-rnn-composes-irish-folk-music>-\n",
        "  * Obama speeches\n",
        "<https://medium.com/@samim/obama-rnn-machine-generated-political-speeches-c8abd18a2ea0>-\n",
        "  * Eminem lyrics\n",
        "<https://soundcloud.com/mrchrisjohnson/recurrent-neural-shady>- (NSFW ;-))\n",
        "  * Research awards\n",
        "<http://karpathy.github.io/2015/05/21/rnn-effectiveness/#comment-2073825449>-\n",
        "  * TED Talks\n",
        "<https://medium.com/@samim/ted-rnn-machine-generated-ted-talks-3dd682b894c0>-\n",
        "  * Movie Titles <http://www.cs.toronto.edu/~graves/handwriting.html>\n",
        "  \n",
        "This notebook contains a reimplementation in Tensorflow. It will let you input a file containing the text you want your generator to mimic, train your model, see the results, and save it for future use.\n",
        "\n",
        "To get started, start running the cells in order, following the instructions at each step. You will need a sizable text file (try at least 1 MB of text) when prompted to upload one. For exploration you can also use the provided text corpus taken from Shakespeare's works.\n",
        "\n",
        "The training cell saves a checkpoint every 30 seconds, so you can check the output of your network and not lose any progress.\n",
        "\n",
        "## Outline\n",
        "\n",
        "This notebook will guide you through the following steps. Roughly speaking, these will be our steps: \n",
        "  * Upload some data\n",
        "  * Set some training parameters (you can just use the defaults for now)\n",
        "  * Define our Model, training loss function, and data input manager\n",
        "  * Train on a cloud GPU\n",
        "  * Save out model and use it to generate some new text.\n",
        "  \n",
        "Design of the RNN is inspired by [this github project](https://github.com/sherjilozair/char-rnn-tensorflow) which was based on Andrej Karpathy's [char-rnn](https://github.com/karpathy/char-rnn). If you'd like to learn more, Andrej's [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a great place to start."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhBCvDKnVstE",
        "colab_type": "text"
      },
      "source": [
        "### Imports and Values Needed to Run this Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67qDGHYCzj6v",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "6d9b799e-3ffd-492c-ee86-406b02c49638"
      },
      "source": [
        "from __future__ import absolute_import, print_function, division\n",
        "from google.colab import files\n",
        "from collections import Counter, defaultdict\n",
        "from copy import deepcopy\n",
        "from IPython.display import clear_output\n",
        "from random import randint\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "CHECKPOINT_DIR = './checkpoints/'  #Checkpoints are temporarily kept here.\n",
        "TEXT_ENCODING = 'utf-8'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBtu02V2ocXC",
        "colab_type": "text"
      },
      "source": [
        "### Get the training data.\n",
        "\n",
        "We can either download the works of Shakespeare to train on or upload our own plain text file that we will be training on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvoepQadkPG6",
        "colab_type": "code",
        "outputId": "895f4c0c-0a4e-4dcb-ad69-e4be52f4436c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "shakespeare_url = \"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\"\n",
        "import urllib\n",
        "file_contents = urllib.urlopen(shakespeare_url).read()\n",
        "file_name = \"shakespeare\"\n",
        "file_contents = file_contents[10501:]  # Skip headers and start at content\n",
        "print(\"An excerpt: \\n\", file_contents[:664])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "An excerpt: \n",
            "                      1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bud buriest thy content,\n",
            "  And tender churl mak'st waste in niggarding:\n",
            "    Pity the world, or else this glutton be,\n",
            "    To eat the world's due, by the grave and thee.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMOW-k6sUgS9",
        "colab_type": "text"
      },
      "source": [
        "If you want to train on your own training data, run the next two cells. Otherwise skip them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7anKDCqMkrQ",
        "colab_type": "code",
        "outputId": "538fb976-f86f-4082-eb50-01636bce27d3",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d037d8fc-2b34-475c-96fc-6f295a507de3\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d037d8fc-2b34-475c-96fc-6f295a507de3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving mix_balance.txt to mix_balance.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtCtMN7FoZYo",
        "colab_type": "code",
        "outputId": "36e45122-31a3-4c20-8273-912d4beb1cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "if uploaded:\n",
        "  if type(uploaded) is not dict: uploaded = uploaded.files  ## Deal with filedit versions\n",
        "  file_bytes = uploaded[uploaded.keys()[0]]\n",
        "  utf8_string = file_bytes.decode(TEXT_ENCODING)\n",
        "  file_contents = utf8_string if files else ''\n",
        "  file_name = uploaded.keys()[0]\n",
        "print(\"An excerpt: \\n\", file_contents[:664])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "An excerpt: \n",
            " I hate how you cant even say black paint anymore Now I have to say \"Leroy can you please paint the fence?\"\r\n",
            "What's the difference between a Jew in Nazi Germany and pizza ? Pizza doesn't scream when you put it in the oven .I'm so sorry.\r\n",
            "I recently went to America.... ...and being there really helped me learn about American culture. So I visited a shop and as I was leaving, the Shopkeeper said \"Have a nice day!\" But I didn't so I sued him.\r\n",
            "Brian raises his hand and says, \"He's in Heaven.\" A Sunday school teacher is concerned that his students might be a little confused about Jesus, so he asks his class, \"Where is Jesus today?\"Brian raises his hand and says\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO0NDmM0VgQU",
        "colab_type": "text"
      },
      "source": [
        "## Set up the recurrent LSTM network \n",
        "\n",
        "Before we can do anything, we have to define what our neural network looks like. This next cell creates a class which will contain the tensorflow graph and training parameters that make up the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAK1D26NKGpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(object):\n",
        "  \"\"\"Represents a Recurrent Neural Network using LSTM cells.\n",
        "\n",
        "  Attributes:\n",
        "    num_layers: The integer number of hidden layers in the RNN.\n",
        "    state_size: The size of the state in each LSTM cell.\n",
        "    num_classes: Number of output classes. (E.g. 256 for Extended ASCII).\n",
        "    batch_size: The number of training sequences to process per step.\n",
        "    sequence_length: The number of chars in a training sequence.\n",
        "    batch_index: Index within the dataset to start the next batch at.\n",
        "    on_gpu_sequences: Generates the training inputs for a single batch.\n",
        "    on_gpu_targets: Generates the training labels for a single batch.\n",
        "    input_symbol: Placeholder for a single label for use during inference.\n",
        "    temperature: Used when sampling outputs. A higher temperature will yield\n",
        "      more variance; a lower one will produce the most likely outputs. Value\n",
        "      should be between 0 and 1.\n",
        "    initial_state: The LSTM State Tuple to initialize the network with. This\n",
        "      will need to be set to the new_state computed by the network each cycle.\n",
        "    logits: Unnormalized probability distribution for the next predicted\n",
        "      label, for each timestep in each sequence.\n",
        "    output_labels: A [batch_size, 1] int32 tensor containing a predicted\n",
        "      label for each sequence in a batch. Only generated in infer mode.\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               rnn_num_layers=1,\n",
        "               rnn_state_size=128,\n",
        "               num_classes=256,\n",
        "               rnn_batch_size=1,\n",
        "               rnn_sequence_length=1):\n",
        "    self.num_layers = rnn_num_layers\n",
        "    self.state_size = rnn_state_size\n",
        "    self.num_classes = num_classes\n",
        "    self.batch_size = rnn_batch_size\n",
        "    self.sequence_length = rnn_sequence_length\n",
        "    self.batch_shape = (self.batch_size, self.sequence_length)\n",
        "    print(\"Built LSTM: \",\n",
        "          self.num_layers ,self.state_size ,self.num_classes ,\n",
        "          self.batch_size ,self.sequence_length ,self.batch_shape)\n",
        "\n",
        "\n",
        "  def build_training_model(self, dropout_rate, data_to_load):\n",
        "    \"\"\"Sets up an RNN model for running a training job.\n",
        "\n",
        "    Args:\n",
        "      dropout_rate: The rate at which weights may be forgotten during training.\n",
        "      data_to_load: A numpy array of containing the training data, with each\n",
        "        element in data_to_load being an integer representing a label. For\n",
        "        example, for Extended ASCII, values may be 0 through 255.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: If mode is data_to_load is None.\n",
        "    \"\"\"\n",
        "    if data_to_load is None:\n",
        "      raise ValueError('To continue, you must upload training data.')\n",
        "    inputs = self._set_up_training_inputs(data_to_load)\n",
        "    self._build_rnn(inputs, dropout_rate)\n",
        "\n",
        "  def build_inference_model(self):\n",
        "    \"\"\"Sets up an RNN model for generating a sequence element by element.\n",
        "    \"\"\"\n",
        "    self.input_symbol = tf.placeholder(shape=[1, 1], dtype=tf.int32)\n",
        "    self.temperature = tf.placeholder(shape=(), dtype=tf.float32,\n",
        "                                      name='temperature')\n",
        "    self.num_options = tf.placeholder(shape=(), dtype=tf.int32,\n",
        "                                      name='num_options')\n",
        "    self._build_rnn(self.input_symbol, 0.0)\n",
        "\n",
        "    self.temperature_modified_logits = tf.squeeze(\n",
        "        self.logits, 0) / self.temperature\n",
        "\n",
        "    #for beam search\n",
        "    self.normalized_probs = tf.nn.softmax(self.logits)\n",
        "\n",
        "    self.output_labels = tf.multinomial(self.temperature_modified_logits,\n",
        "                                        self.num_options)\n",
        "\n",
        "  def _set_up_training_inputs(self, data):\n",
        "    self.batch_index = tf.placeholder(shape=(), dtype=tf.int32)\n",
        "    batch_input_length = self.batch_size * self.sequence_length\n",
        "\n",
        "    input_window = tf.slice(tf.constant(data, dtype=tf.int32),\n",
        "                            [self.batch_index],\n",
        "                            [batch_input_length + 1])\n",
        "\n",
        "    self.on_gpu_sequences = tf.reshape(\n",
        "        tf.slice(input_window, [0], [batch_input_length]), self.batch_shape)\n",
        "\n",
        "    self.on_gpu_targets = tf.reshape(\n",
        "        tf.slice(input_window, [1], [batch_input_length]), self.batch_shape)\n",
        "\n",
        "    return self.on_gpu_sequences\n",
        "\n",
        "  def _build_rnn(self, inputs, dropout_rate):\n",
        "    \"\"\"Generates an RNN model using the passed functions.\n",
        "\n",
        "    Args:\n",
        "      inputs: int32 Tensor with shape [batch_size, sequence_length] containing\n",
        "        input labels.\n",
        "      dropout_rate: A floating point value determining the chance that a weight\n",
        "        is forgotten during evaluation.\n",
        "    \"\"\"\n",
        "    # Alias some commonly used functions\n",
        "    dropout_wrapper = tf.contrib.rnn.DropoutWrapper\n",
        "    lstm_cell = tf.contrib.rnn.LSTMCell\n",
        "    multi_rnn_cell = tf.contrib.rnn.MultiRNNCell\n",
        "\n",
        "    self._cell = multi_rnn_cell(\n",
        "        [dropout_wrapper(lstm_cell(self.state_size), 1.0, 1.0 - dropout_rate)\n",
        "         for _ in range(self.num_layers)])\n",
        "\n",
        "    self.initial_state = self._cell.zero_state(self.batch_size, tf.float32)\n",
        "\n",
        "    embedding = tf.get_variable('embedding',\n",
        "                                [self.num_classes, self.state_size])\n",
        "\n",
        "    embedding_input = tf.nn.embedding_lookup(embedding, inputs)\n",
        "    output, self.new_state = tf.nn.dynamic_rnn(self._cell, embedding_input,\n",
        "                                               initial_state=self.initial_state)\n",
        "\n",
        "    self.logits = tf.contrib.layers.fully_connected(output, self.num_classes,\n",
        "                                                    activation_fn=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVEdNYclTSdv",
        "colab_type": "text"
      },
      "source": [
        "### Let's define our training parameters.\n",
        "Feel free to leave these untouched at their default values and just run this cell as is. Later, you can come back here and experiment wth these. \n",
        "These parameters are just for training. Further down at the inference step, we'll define parameters for the text-generation step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRPTh7_A2u80",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "num_layers = 2\n",
        "state_size = 256\n",
        "batch_size = 64\n",
        "sequence_length = 256\n",
        "num_training_steps = 30000 # Takes about 40 minuets \n",
        "steps_per_epoch = 500\n",
        "learning_rate = 0.002\n",
        "learning_rate_decay = 0.95\n",
        "gradient_clipping = 5.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ2NdzM5RHyK",
        "colab_type": "text"
      },
      "source": [
        "###Define your loss function\n",
        "Loss is a measure of how well the neural network is modeling the data distribution. \n",
        "\n",
        "Pass in your logits and the targets you're training against. In this case, target_weights is a set of multipliers that will put higher emphasis on certain outputs. In this notebook, we'll give all outputs equal importance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbBZuBT6NhVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_loss(logits, targets, target_weights):\n",
        "  with tf.name_scope('loss'):\n",
        "    return tf.contrib.seq2seq.sequence_loss(\n",
        "        logits,\n",
        "        targets,\n",
        "        target_weights,\n",
        "        average_across_timesteps=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svir_HYvpHQn",
        "colab_type": "text"
      },
      "source": [
        "### Define your optimizer\n",
        "This tells Tensorflow how to reduce the loss. We will use the popular [ADAM algorithm](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swLcZqsePGAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_optimizer(loss, initial_learning_rate, gradient_clipping, global_step,\n",
        "                  decay_steps, decay_rate):\n",
        "\n",
        "  with tf.name_scope('optimizer'):\n",
        "    computed_learning_rate = tf.train.exponential_decay(\n",
        "        initial_learning_rate,\n",
        "        global_step,\n",
        "        decay_steps,\n",
        "        decay_rate,\n",
        "        staircase=True)\n",
        "\n",
        "    optimizer = tf.train.AdamOptimizer(computed_learning_rate)\n",
        "    trained_vars = tf.trainable_variables()\n",
        "    gradients, _ = tf.clip_by_global_norm(\n",
        "        tf.gradients(loss, trained_vars),\n",
        "        gradient_clipping)\n",
        "    training_op = optimizer.apply_gradients(\n",
        "        zip(gradients, trained_vars),\n",
        "        global_step=global_step)\n",
        "\n",
        "    return training_op, computed_learning_rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60O5Dw_Hr5-s",
        "colab_type": "text"
      },
      "source": [
        "### This class will let us view the progress of our training as it progresses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmfVg_eEeaOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LossPlotter(object):\n",
        "  def __init__(self, history_length):\n",
        "    self.global_steps = []\n",
        "    self.losses = []\n",
        "    self.averaged_loss_x = []\n",
        "    self.averaged_loss_y = []\n",
        "    self.history_length = history_length\n",
        "\n",
        "  def draw_plots(self):\n",
        "    self._update_averages(self.global_steps, self.losses,\n",
        "                          self.averaged_loss_x, self.averaged_loss_y)\n",
        "\n",
        "    plt.title('Average Loss Over Time')\n",
        "    plt.xlabel('Global Step')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(self.averaged_loss_x, self.averaged_loss_y, label='Loss/Time (Avg)')\n",
        "    plt.plot()\n",
        "    plt.plot(self.global_steps, self.losses,\n",
        "             label='Loss/Time (Last %d)' % self.history_length,\n",
        "             alpha=.1, color='r')\n",
        "    plt.plot()\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.title('Loss for the last 100 Steps')\n",
        "    plt.xlabel('Global Step')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(self.global_steps, self.losses,\n",
        "             label='Loss/Time (Last %d)' % self.history_length, color='r')\n",
        "    plt.plot()\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # The notebook will be slowed down at the end of training if we plot the\n",
        "    # entire history of raw data. Plot only the last 100 steps of raw data,\n",
        "    # and the average of each 100 batches. Don't keep unused data.\n",
        "    self.global_steps = []\n",
        "    self.losses = []\n",
        "    self.learning_rates = []\n",
        "\n",
        "  def log_step(self, global_step, loss):\n",
        "    self.global_steps.append(global_step)\n",
        "    self.losses.append(loss)\n",
        "\n",
        "  def _update_averages(self, x_list, y_list,\n",
        "                       averaged_data_x, averaged_data_y):\n",
        "    averaged_data_x.append(x_list[-1])\n",
        "    averaged_data_y.append(sum(y_list) / self.history_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPwFDEiZhr6x",
        "colab_type": "text"
      },
      "source": [
        "## Now, we're going to start training our model.\n",
        "\n",
        "This could take a while, so you might want to grab a coffee. Every 30 seconds of training, we're going to save a checkpoint to make sure we don't lose our progress. To monitor the progress of your training, feel free to stop the training every once in a while and run the inference cell to generate text with your model!\n",
        "\n",
        "First, we will need to turn the plain text file into arrays of tokens (and, later,  back). To do this we will use this token mapper helper class:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n98dKVTzkmpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "class TokenMapper(object):\n",
        "  def __init__(self):\n",
        "    self.token_mapping = {}\n",
        "    self.reverse_token_mapping = {}\n",
        "  def buildFromData(self, utf8_string, limit=0.00004):\n",
        "    print(\"Build token dictionary.\")\n",
        "    total_num = len(utf8_string)\n",
        "    sorted_tokens = sorted(Counter(utf8_string.decode('utf8')).items(), \n",
        "                           key=lambda x: -x[1])\n",
        "    # Filter tokens: Only allow printable characters (not control chars) and\n",
        "    # limit to ones that are resonably common, i.e. skip strange esoteric \n",
        "    # characters in order to reduce the dictionary size.\n",
        "    filtered_tokens = filter(lambda t: t[0] in string.printable or \n",
        "                             float(t[1])/total_num > limit, sorted_tokens)\n",
        "    tokens, counts = zip(*filtered_tokens)\n",
        "    self.token_mapping = dict(zip(tokens, range(len(tokens))))\n",
        "    for c in string.printable:\n",
        "      if c not in self.token_mapping:\n",
        "        print(\"Skipped token for: \", c)\n",
        "    self.reverse_token_mapping = {\n",
        "        val: key for key, val in self.token_mapping.items()}\n",
        "    print(\"Created dictionary: %d tokens\"%len(self.token_mapping))\n",
        "  \n",
        "  def mapchar(self, char):\n",
        "    if char in self.token_mapping:\n",
        "      return self.token_mapping[char]\n",
        "    else:\n",
        "      return self.token_mapping[' ']\n",
        "  \n",
        "  def mapstring(self, utf8_string):\n",
        "    return [self.mapchar(c) for c in utf8_string]\n",
        "  \n",
        "  def maptoken(self, token):\n",
        "    return self.reverse_token_mapping[token]\n",
        "  \n",
        "  def maptokens(self, int_array):\n",
        "    return ''.join([self.reverse_token_mapping[c] for c in int_array])\n",
        "  \n",
        "  def size(self):\n",
        "    return len(self.token_mapping)\n",
        "  \n",
        "  def alphabet(self):\n",
        "    return ''.join([k for k,v in sorted(self.token_mapping.items(),key=itemgetter(1))])\n",
        "\n",
        "  def print(self):\n",
        "    for k,v in sorted(self.token_mapping.items(),key=itemgetter(1)): print(k, v)\n",
        "  \n",
        "  def save(self, path):\n",
        "    with open(path, 'wb') as json_file:\n",
        "      json.dump(self.token_mapping, json_file)\n",
        "  \n",
        "  def restore(self, path):\n",
        "    with open(path, 'r') as json_file:\n",
        "      self.token_mapping = {}\n",
        "      self.token_mapping.update(json.load(json_file))\n",
        "      self.reverse_token_mapping = {val: key for key, val in self.token_mapping.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XTGD7fxfEuK",
        "colab_type": "text"
      },
      "source": [
        "Now convert the raw input into a list of tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RiHe0bUo9eP",
        "colab_type": "code",
        "outputId": "d83f6cda-0dad-480f-96cb-88d7c9a82bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "# Clean the checkpoint directory and make a fresh one\n",
        "!rm -rf {CHECKPOINT_DIR}\n",
        "!mkdir {CHECKPOINT_DIR}\n",
        "!ls -lt\n",
        "\n",
        "chars_in_batch = (sequence_length * batch_size)\n",
        "file_len = len(file_contents)\n",
        "unique_sequential_batches = file_len // chars_in_batch\n",
        "\n",
        "mapper = TokenMapper()\n",
        "mapper.buildFromData(file_contents)\n",
        "mapper.save(''.join([CHECKPOINT_DIR, 'token_mapping.json']))\n",
        "\n",
        "input_values = mapper.mapstring(file_contents)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 136\n",
            "drwxr-xr-x 2 root root   4096 Jan  7 15:39 checkpoints\n",
            "-rw-r--r-- 1 root root 128457 Jan  7 15:38 mix_balance.txt\n",
            "drwxr-xr-x 1 root root   4096 Dec 18 16:52 sample_data\n",
            "Build token dictionary.\n",
            "Skipped token for:  +\n",
            "Skipped token for:  =\n",
            "Skipped token for:  @\n",
            "Skipped token for:  \\\n",
            "Skipped token for:  ^\n",
            "Skipped token for:  {\n",
            "Skipped token for:  |\n",
            "Skipped token for:  }\n",
            "Skipped token for:  ~\n",
            "Skipped token for:  \u000b\n",
            "Skipped token for:  \f\n",
            "Created dictionary: 89 tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5He_ECNJc61",
        "colab_type": "text"
      },
      "source": [
        "###First, we'll build our neural network and add our training operations to the Tensorflow graph. \n",
        "If you're continuing training after testing your generator, run the next three cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgXvABhpJa1f",
        "colab_type": "code",
        "outputId": "1530ef5b-862c-41e7-dfa1-1016399d4227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "print('Constructing model...')\n",
        "\n",
        "model = RNN(\n",
        "    rnn_num_layers=num_layers,\n",
        "    rnn_state_size=state_size,\n",
        "    num_classes=mapper.size(),\n",
        "    rnn_batch_size=batch_size,\n",
        "    rnn_sequence_length=sequence_length)\n",
        "\n",
        "model.build_training_model(0.05, np.asarray(input_values))\n",
        "print('Constructed model successfully.')\n",
        "\n",
        "print('Setting up training session...')\n",
        "neutral_target_weights = tf.constant(\n",
        "    np.ones(model.batch_shape),\n",
        "    tf.float32\n",
        ")\n",
        "loss = get_loss(model.logits, model.on_gpu_targets, neutral_target_weights)\n",
        "global_step = tf.get_variable('global_step', shape=(), trainable=False,\n",
        "                              dtype=tf.int32)\n",
        "training_step, computed_learning_rate = get_optimizer(\n",
        "    loss,\n",
        "    learning_rate,\n",
        "    gradient_clipping,\n",
        "    global_step,\n",
        "    steps_per_epoch,\n",
        "    learning_rate_decay\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0107 15:39:44.184161 139650574518144 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Constructing model...\n",
            "Built LSTM:  2 256 89 64 256 (64, 256)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0107 15:39:46.377995 139650574518144 deprecation.py:323] From <ipython-input-5-12171759f484>:109: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0107 15:39:46.387654 139650574518144 deprecation.py:323] From <ipython-input-5-12171759f484>:109: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0107 15:39:46.423824 139650574518144 deprecation.py:323] From <ipython-input-5-12171759f484>:118: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "W0107 15:39:46.492635 139650574518144 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "W0107 15:39:46.503180 139650574518144 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0107 15:39:46.591707 139650574518144 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Constructed model successfully.\n",
            "Setting up training session...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0107 15:39:46.960716 139650574518144 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNKzEmaRj5SF",
        "colab_type": "text"
      },
      "source": [
        "The supervisor will manage the training flow and checkpointing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t90StbXJj4jt",
        "colab_type": "code",
        "outputId": "fd34379b-ce15-46f5-f829-f0489f1101a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "# Create a supervisor that will checkpoint the model in the CHECKPOINT_DIR\n",
        "sv = tf.train.Supervisor(\n",
        "    logdir=CHECKPOINT_DIR,\n",
        "    global_step=global_step,\n",
        "    save_model_secs=30)\n",
        "print('Training session ready.')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0107 15:39:50.284068 139650574518144 deprecation.py:323] From <ipython-input-13-4ba04cba093f>:4: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training session ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tfXYyumK5z6",
        "colab_type": "text"
      },
      "source": [
        "###This next cell will begin the training cycle. \n",
        "First, we will attempt to pick up training where we left off, if a previous checkpoint exists, then continue the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wfsDMuLLUr3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c29b9462-2bef-4086-f9f7-db210beca514"
      },
      "source": [
        "from datetime import datetime\n",
        "start_time = datetime.now()\n",
        "\n",
        "with sv.managed_session(config=config) as sess:\n",
        "  print('Training supervisor successfully initialized all variables.')\n",
        "  if not file_len:\n",
        "    raise ValueError('To continue, you must upload training data.')\n",
        "  elif file_len < chars_in_batch:\n",
        "    raise ValueError('To continue, you must upload a larger set of data.')\n",
        "\n",
        "  plotter = LossPlotter(100)\n",
        "  step_number = sess.run(global_step)\n",
        "  zero_state = sess.run([model.initial_state])\n",
        "  max_batch_index = (unique_sequential_batches - 1) * chars_in_batch\n",
        "  while not sv.should_stop() and step_number < num_training_steps:\n",
        "    feed_dict = {\n",
        "        model.batch_index: randint(0, max_batch_index),\n",
        "        model.initial_state: zero_state\n",
        "        }\n",
        "    [_, _, training_loss, step_number, current_learning_rate, _] = sess.run(\n",
        "        [model.on_gpu_sequences,\n",
        "         model.on_gpu_targets,\n",
        "         loss,\n",
        "         global_step,\n",
        "         computed_learning_rate,\n",
        "         training_step],\n",
        "        feed_dict)\n",
        "    plotter.log_step(step_number, training_loss)\n",
        "    if step_number % 100 == 0:\n",
        "      clear_output(True)\n",
        "      plotter.draw_plots()\n",
        "      print('Latest checkpoint is: %s' %\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_DIR))\n",
        "      print('Learning Rate is: %f' %\n",
        "            current_learning_rate)\n",
        "\n",
        "    if step_number % 10 == 0:\n",
        "      print('global step %d, loss=%f' % (step_number, training_loss))\n",
        "\n",
        "clear_output(True)\n",
        "\n",
        "print('Training completed in HH:MM:SS = ', datetime.now()-start_time)\n",
        "print('Latest checkpoint is: %s' %\n",
        "      tf.train.latest_checkpoint(CHECKPOINT_DIR))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Latest checkpoint is: ./checkpoints/model.ckpt-14197\n",
            "Learning Rate is: 0.000476\n",
            "global step 14200, loss=0.097953\n",
            "global step 14210, loss=0.102919\n",
            "global step 14220, loss=0.099777\n",
            "global step 14230, loss=0.094137\n",
            "global step 14240, loss=0.092679\n",
            "global step 14250, loss=0.104869\n",
            "global step 14260, loss=0.097875\n",
            "global step 14270, loss=0.100895\n",
            "global step 14280, loss=0.097433\n",
            "global step 14290, loss=0.101801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0107 17:15:41.591588 139650574518144 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:12: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9a66b16d51f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m          \u001b[0mcomputed_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m          training_step],\n\u001b[0;32m---> 27\u001b[0;31m         feed_dict)\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep_number\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rpr5zK1UUlEd",
        "colab_type": "text"
      },
      "source": [
        "## Now, we're going to generate some text!\n",
        "\n",
        "Here, we'll use the **Beam Search** algorithm to generate some text with our trained model. Beam Search picks N possible next options from each of the current options at every step. This way, if the generator picks an item leading to a bad decision down the line, it can toss the bad result out and keep going with a more likely one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc8W1I0bJy-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BeamSearchCandidate(object):\n",
        "  \"\"\"Represents a node within the search space during Beam Search.\n",
        "\n",
        "  Attributes:\n",
        "    state: The resulting RNN state after the given sequence has been generated.\n",
        "    sequence: The sequence of selections leading to this node.\n",
        "    probability: The probability of the sequence occurring, computed as the sum\n",
        "      of the probabilty of each character in the sequence at its respective\n",
        "      step.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, init_state, sequence, probability):\n",
        "    self.state = init_state\n",
        "    self.sequence = sequence\n",
        "    self.probability = probability\n",
        "\n",
        "  def search_from(self, tf_sess, rnn_model, temperature, num_options):\n",
        "    \"\"\"Expands the num_options most likely next elements in the sequence.\n",
        "\n",
        "    Args:\n",
        "      tf_sess: The Tensorflow session containing the rnn_model.\n",
        "      rnn_model: The RNN to use to generate the next element in the sequence.\n",
        "      temperature: Modifies the probabilities of each character, placing\n",
        "        more emphasis on higher probabilities as the value approaches 0.\n",
        "      num_options: How many potential next options to expand from this one.\n",
        "\n",
        "    Returns: A list of BeamSearchCandidate objects descended from this node.\n",
        "    \"\"\"\n",
        "    expanded_set = []\n",
        "    feed = {rnn_model.input_symbol: np.array([[self.sequence[-1]]]),\n",
        "            rnn_model.initial_state: self.state,\n",
        "            rnn_model.temperature: temperature,\n",
        "            rnn_model.num_options: num_options}\n",
        "    [predictions, probabilities, new_state] = tf_sess.run(\n",
        "        [rnn_model.output_labels,\n",
        "         rnn_model.normalized_probs,\n",
        "         rnn_model.new_state], feed)\n",
        "    # Get the indices of the num_beams next picks\n",
        "    picks = [predictions[0][x] for x in range(len(predictions[0]))]\n",
        "    for new_char in picks:\n",
        "      new_seq = deepcopy(self.sequence)\n",
        "      new_seq.append(new_char)\n",
        "      expanded_set.append(\n",
        "          BeamSearchCandidate(new_state, new_seq,\n",
        "                              probabilities[0][0][new_char] + self.probability))\n",
        "    return expanded_set\n",
        "\n",
        "  def __eq__(self, other):\n",
        "    return self.sequence == other.sequence\n",
        "\n",
        "  def __ne__(self, other):\n",
        "    return not self.__eq__(other)\n",
        "\n",
        "  def __hash__(self):\n",
        "    return hash(self.sequence())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97aGkvJGNFUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def beam_search_generate_sequence(tf_sess, rnn_model, primer, temperature=0.85,\n",
        "                                  termination_condition=None, num_beams=5):\n",
        "  \"\"\"Implements a sequence generator using Beam Search.\n",
        "\n",
        "  Args:\n",
        "    tf_sess: The Tensorflow session containing the rnn_model.\n",
        "    rnn_model: The RNN to use to generate the next element in the sequence.\n",
        "    temperature: Controls how 'Creative' the generated sequence is. Values\n",
        "      close to 0 tend to generate the most likely sequence, while values\n",
        "      closer to 1 generate more original sequences. Acceptable values are\n",
        "      within (0, 1].\n",
        "    termination_condition: A function taking one parameter, a list of\n",
        "      integers, that returns True when a condition is met that signals to the\n",
        "      RNN to return what it has generated so far.\n",
        "    num_beams: The number of possible sequences to keep at each step of the\n",
        "      generation process.\n",
        "\n",
        "  Returns: A list of at most num_beams BeamSearchCandidate objects.\n",
        "  \"\"\"\n",
        "  candidates = []\n",
        "\n",
        "  rnn_current_state = sess.run([rnn_model.initial_state])\n",
        "  #Initialize the state for the primer\n",
        "  for primer_val in primer[:-1]:\n",
        "    feed = {rnn_model.input_symbol: np.array([[primer_val]]),\n",
        "            rnn_model.initial_state: rnn_current_state\n",
        "           }\n",
        "    [rnn_current_state] = tf_sess.run([rnn_model.new_state], feed)\n",
        "\n",
        "  candidates.append(BeamSearchCandidate(rnn_current_state, primer, num_beams))\n",
        "\n",
        "  while True not in [termination_condition(x.sequence) for x in candidates]:\n",
        "    new_candidates = []\n",
        "    for candidate in candidates:\n",
        "      expanded_candidates = candidate.search_from(\n",
        "          tf_sess, rnn_model, temperature, num_beams)\n",
        "      for new in expanded_candidates:\n",
        "        if new not in new_candidates:\n",
        "          #do not reevaluate duplicates\n",
        "          new_candidates.append(new)\n",
        "    candidates = sorted(new_candidates,\n",
        "                        key=lambda x: x.probability, reverse=True)[:num_beams]\n",
        "\n",
        "  return [c for c in candidates if termination_condition(c.sequence)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj0w_Vgs-oMJ",
        "colab_type": "text"
      },
      "source": [
        "Input something to start your generated text with, and set how characters long you want the text to be.\n",
        "\"Creativity\" refers to how much emphasis your neural network puts on matching a pattern. If you notice looping in the output, try raising this value. If your output seems too random, try lowering it a bit.\n",
        "If the results don't look too great in general, run the three training cells again for a bit longer. The lower your loss, the more closely your generated text will match the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAsyTCZvdFn5",
        "colab_type": "code",
        "outputId": "4b81e501-b890-417f-f4a0-ed7400bdb7bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.InteractiveSession(config=config)\n",
        "\n",
        "model = RNN(\n",
        "    rnn_num_layers=num_layers,\n",
        "    rnn_state_size=state_size,\n",
        "    num_classes=mapper.size(),\n",
        "    rnn_batch_size=1,\n",
        "    rnn_sequence_length=1)\n",
        "\n",
        "model.build_inference_model()\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "saver = tf.train.Saver(tf.global_variables())\n",
        "ckpt = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
        "saver.restore(sess, ckpt)\n",
        "\n",
        "def gen(start_with, pred, creativity):\n",
        "  int_array = mapper.mapstring(start_with)\n",
        "  candidates = beam_search_generate_sequence(\n",
        "      sess, model, int_array, temperature=creativity,\n",
        "      termination_condition=pred,\n",
        "      num_beams=1)\n",
        "  gentext = mapper.maptokens(candidates[0].sequence)\n",
        "  return gentext\n",
        "\n",
        "def lengthlimit(n):\n",
        "  return lambda text: len(text)>n\n",
        "def sentences(n):\n",
        "  return lambda text: mapper.maptokens(text).count(\".\")>=n\n",
        "def paragraph():\n",
        "  return lambda text: mapper.maptokens(text).count(\"\\n\")>0\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0107 17:15:53.629810 139650574518144 deprecation.py:323] From <ipython-input-5-12171759f484>:75: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Built LSTM:  2 256 89 1 1 (1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09ccehpqVKR8",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "9091d172-e1ae-4856-c40e-d0b1455a8ee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "length_of_generated_text = 88\n",
        "creativity = 0.88  # Should be greater than 0 but less than 1\n",
        "\n",
        "print(gen(\"How \", lengthlimit(length_of_generated_text), creativity))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How shorting and for a bit longer when, I hear the traveler, as he puts his foot on top o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klTwA-RrFwR0",
        "colab_type": "text"
      },
      "source": [
        "## Let's save a copy of our trained RNN so we can do all kinds of cool things with it later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdxjJaayFuhS",
        "colab_type": "code",
        "outputId": "a80fc89e-6e86-4e1e-9a4d-c2ed173e8ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "save_model_to_drive = False  ## Set this to true to save directly to Google Drive.\n",
        "\n",
        "def save_model_hyperparameters(path):\n",
        "  with open(path, 'w')  as json_file:\n",
        "    model_params = {\n",
        "        'num_layers': model.num_layers,\n",
        "        'state_size': model.state_size,\n",
        "        'num_classes': model.num_classes\n",
        "    }\n",
        "    json.dump(model_params, json_file)\n",
        "\n",
        "def save_to_drive(title, content):\n",
        "  # Install the PyDrive wrapper & import libraries.\n",
        "  !pip install -U -q PyDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "\n",
        "  # Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "  newfile = drive.CreateFile({'title': title})\n",
        "  newfile.SetContentFile(content)\n",
        "  newfile.Upload()\n",
        "  print('Uploaded file with ID %s as %s'% (newfile.get('id'),\n",
        "         archive_name))\n",
        "    \n",
        "archive_name = ''.join([file_name,'_seedbank_char-rnn.zip'])\n",
        "latest_model = tf.train.latest_checkpoint(CHECKPOINT_DIR).split('/')[2]\n",
        "checkpoints_archive_path = ''.join(['./exports/',archive_name])\n",
        "if not latest_model:\n",
        "  raise ValueError('You must train a model before you can export one.')\n",
        "  \n",
        "%system mkdir exports\n",
        "%rm -f {checkpoints_archive_path}\n",
        "mapper.save(''.join([CHECKPOINT_DIR, 'token_mapping.json']))\n",
        "save_model_hyperparameters(''.join([CHECKPOINT_DIR, 'model_attributes.json']))\n",
        "%system zip '{checkpoints_archive_path}' -@ '{CHECKPOINT_DIR}checkpoint' \\\n",
        "            '{CHECKPOINT_DIR}token_mapping.json' \\\n",
        "            '{CHECKPOINT_DIR}model_attributes.json' \\\n",
        "            '{CHECKPOINT_DIR}{latest_model}.'*\n",
        "\n",
        "if save_model_to_drive:\n",
        "  save_to_drive(archive_name, checkpoints_archive_path)\n",
        "else:\n",
        "  files.download(checkpoints_archive_path)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1dQEv67yQe10ccsW13sJx89ilhCDmXzxP as shakespeare_seedbank_char-rnn.zip\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}